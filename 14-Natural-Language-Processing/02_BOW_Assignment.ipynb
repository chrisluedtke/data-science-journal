{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Representations: Bag-Of-Words Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\City_Year\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/job_listings_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use NLTK to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(doc):\n",
    "    import re\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    \n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # strip HTML\n",
    "    doc = re.sub('<[^<]+?>', '', doc)\n",
    "    # Tokenize by word\n",
    "    tokens = word_tokenize(doc)\n",
    "    # Strip punctuation from within words\n",
    "    tokens = [x.lower().translate(table) \n",
    "              for x in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "df['tokenized_desc'] = df.apply(lambda row: tokenize_words(row['description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [b, job, requirement, nconceptual, understandi...\n",
       "1    [bjob, descriptionnnas, data, scientist, help,...\n",
       "2    [ba, data, scientist, working, consulting, sid...\n",
       "3    [b, monthcontractunder, general, supervision, ...\n",
       "4    [blocation, usa, multiple, year, analytics, ex...\n",
       "Name: tokenized_desc, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure why the 'b' from the byte string is converted\n",
    "df['tokenized_desc'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# List of document strings as text\n",
    "token_list = df['tokenized_desc'].to_list()\n",
    "token_list = [\" \".join(doc) for doc in token_list]\n",
    "# Instantiate vectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "bag_of_words = vectorizer.fit_transform(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 14122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaai</th>\n",
       "      <th>aaeeo</th>\n",
       "      <th>ab</th>\n",
       "      <th>abernathy</th>\n",
       "      <th>abilitiesnability</th>\n",
       "      <th>abilitiesndevelops</th>\n",
       "      <th>abilitiesnexperience</th>\n",
       "      <th>abilitiesnninterpersonal</th>\n",
       "      <th>abilitiesnproblem</th>\n",
       "      <th>abilitiesnsolid</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zonesnability</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaai  aaeeo  ab  abernathy  abilitiesnability  abilitiesndevelops  \\\n",
       "0     0      0   0          0                  0                   0   \n",
       "1     0      0   0          0                  0                   0   \n",
       "2     0      0   0          0                  0                   0   \n",
       "3     0      0   0          0                  0                   0   \n",
       "4     0      0   0          0                  0                   0   \n",
       "\n",
       "   abilitiesnexperience  abilitiesnninterpersonal  abilitiesnproblem  \\\n",
       "0                     0                         0                  0   \n",
       "1                     0                         0                  0   \n",
       "2                     0                         0                  0   \n",
       "3                     0                         0                  0   \n",
       "4                     0                         0                  0   \n",
       "\n",
       "   abilitiesnsolid  ...  zenreach  zero  zeus  zf  zheng  zillow  \\\n",
       "0                0  ...         0     0     0   0      0       0   \n",
       "1                0  ...         0     0     0   0      0       0   \n",
       "2                0  ...         0     0     0   0      0       0   \n",
       "3                0  ...         0     0     0   0      1       0   \n",
       "4                0  ...         0     0     0   0      0       0   \n",
       "\n",
       "   zonesnability  zoom  zuckerberg  zurich  \n",
       "0              0     0           0       0  \n",
       "1              0     0           0       0  \n",
       "2              0     0           0       0  \n",
       "3              0     0           0       0  \n",
       "4              0     0           0       0  \n",
       "\n",
       "[5 rows x 14122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df = pd.DataFrame(bag_of_words.toarray(), \n",
    "                      columns=vectorizer.get_feature_names())\n",
    "print(bow_df.shape)\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "top_10 = bow_df.sum(axis=0).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_10.plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>business</th>\n",
       "      <th>customer</th>\n",
       "      <th>data</th>\n",
       "      <th>experience</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>new</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>product</th>\n",
       "      <th>science</th>\n",
       "      <th>scientist</th>\n",
       "      <th>skill</th>\n",
       "      <th>solution</th>\n",
       "      <th>statistical</th>\n",
       "      <th>team</th>\n",
       "      <th>technology</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204459</td>\n",
       "      <td>0.462075</td>\n",
       "      <td>0.272773</td>\n",
       "      <td>0.290315</td>\n",
       "      <td>0.606359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111835</td>\n",
       "      <td>0.301943</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.396911</td>\n",
       "      <td>0.351458</td>\n",
       "      <td>0.374060</td>\n",
       "      <td>0.130212</td>\n",
       "      <td>0.268672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>0.218326</td>\n",
       "      <td>0.109691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.204320</td>\n",
       "      <td>0.426749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178882</td>\n",
       "      <td>0.359494</td>\n",
       "      <td>0.211192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297992</td>\n",
       "      <td>0.274504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494686</td>\n",
       "      <td>0.395779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analytics  business  customer      data  experience  learning  \\\n",
       "0       0.0   0.000000  0.000000  0.000000  0.204459    0.462075  0.272773   \n",
       "1       0.0   0.000000  0.111835  0.301943  0.351250    0.396911  0.351458   \n",
       "2       0.0   0.000000  0.549784  0.000000  0.431687    0.000000  0.191975   \n",
       "3       0.0   0.000000  0.000000  0.000000  0.389583    0.000000  0.000000   \n",
       "4       0.0   0.494686  0.395779  0.000000  0.621527    0.000000  0.000000   \n",
       "\n",
       "    machine     model       new  opportunity   product   science  scientist  \\\n",
       "0  0.290315  0.606359  0.000000     0.000000  0.000000  0.254170   0.000000   \n",
       "1  0.374060  0.130212  0.268672     0.000000  0.253194  0.218326   0.109691   \n",
       "2  0.204320  0.426749  0.000000     0.000000  0.000000  0.178882   0.359494   \n",
       "3  0.000000  0.000000  0.297992     0.274504  0.000000  0.000000   0.000000   \n",
       "4  0.000000  0.460813  0.000000     0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "      skill  solution  statistical      team  technology      work  \n",
       "0  0.300078       0.0     0.000000  0.000000         0.0  0.252340  \n",
       "1  0.000000       0.0     0.000000  0.303377         0.0  0.216754  \n",
       "2  0.211192       0.0     0.211734  0.000000         0.0  0.000000  \n",
       "3  0.000000       0.0     0.000000  0.672970         0.0  0.480816  \n",
       "4  0.000000       0.0     0.000000  0.000000         0.0  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = df['tokenized_desc'].to_list()\n",
    "token_list = [\" \".join(doc) for doc in token_list]\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 20)\n",
    "feature_matrix = tfidf.fit_transform(token_list)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "df = pd.DataFrame(data=feature_matrix.toarray(), \n",
    "                  columns=feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
