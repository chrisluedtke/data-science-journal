{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASfGeMfI6Kgs"
   },
   "source": [
    "# Word Embeddings Assignment\n",
    "\n",
    "### Use Word2Vec to train your own model on a dataset.\n",
    "\n",
    "1) **Optional** - Find your own dataset of documents to train you model on. You are going to need a lot of data, so it's probably not realistic to scrape data for this assignment given the time constraints that we're working under. Try to find a dataset that has > 5000 documents.\n",
    "\n",
    "- If you can't find a dataset to use try this one: <https://www.kaggle.com/c/quora-question-pairs>\n",
    "\n",
    "2) Clean/Tokenize the documents.\n",
    "\n",
    "3) Vectorize the model using Word2Vec and explore the results using each of the following at least one time:\n",
    "\n",
    "- your_model.wv.most_similar()\n",
    "- your_model.wv.similarity()\n",
    "- your_model.wv.doesn't_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy5lYo4K8wEy"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkzdOZm38yQ_"
   },
   "source": [
    "### Stretch Goals:\n",
    "\n",
    "1) Use Doc2Vec to train a model on your dataset, and then provide model with a new document and let it find similar documents.\n",
    "\n",
    "2) Download the pre-trained word vectors from Google. Access the pre-trained vectors via the following link: https://code.google.com/archive/p/word2vec\n",
    "\n",
    "  - Load the pre-trained word vectors and train the Word2vec model\n",
    "\n",
    "  - Examine the first 100 keys or words of the vocabulary\n",
    "\n",
    "  - Outputs the vector representation for a select set of words - the words can be of your choice\n",
    "\n",
    "  - Examine the similarity between words - the words can be of your choice\n",
    "\n",
    "  - For example:\n",
    "\n",
    "    - model.similarity('house', 'bungalow')\n",
    "\n",
    "    - model.similarity('house', 'umbrella')\n",
    "    \n",
    "3) Word2Vec is not the latest or greatest wording embedding model, but it has been around long enough to have well developed APIs in several of the major packages. Try one of the State of the Art (SoA) embeddings models on your dataset. The state of the art models are BERT and Elmo (and yes, that is a pun). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gakr5rP76IAJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_424_Word_Embeddings_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
